{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from utils.modelLoader import ModelLoader\n",
    "import numpy as np\n",
    "from utils.utilities import buildRunName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_json(\"../data_meta/age/meta_full_str_grouped.json\")\n",
    "images['Age'] = images['Age'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17179 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=images,\n",
    "    x_col='Filepath',\n",
    "    y_col='Age',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4294 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=images,\n",
    "    x_col='Filepath',\n",
    "    y_col='Age',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelLoader().loadMobileNetV1Age(train_images, False, False, train_images.class_indices.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "537/537 [==============================] - 399s 735ms/step - loss: 7.1437 - accuracy: 0.2242 - val_loss: 7.3889 - val_accuracy: 0.2445\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.9651 - accuracy: 0.2346 - val_loss: 6.9644 - val_accuracy: 0.0419\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 6.9026 - accuracy: 0.2332 - val_loss: 6.9097 - val_accuracy: 0.2445\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.8776 - accuracy: 0.2373 - val_loss: 7.0861 - val_accuracy: 0.0398\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - 87s 161ms/step - loss: 6.8577 - accuracy: 0.2444 - val_loss: 11.7187 - val_accuracy: 0.0398\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.7867 - accuracy: 0.2589 - val_loss: 7.3747 - val_accuracy: 0.1244\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 6.7560 - accuracy: 0.2678 - val_loss: 9.9626 - val_accuracy: 0.0710\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 6.8391 - accuracy: 0.2475 - val_loss: 6.8177 - val_accuracy: 0.2517\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.7445 - accuracy: 0.2667 - val_loss: 8.3297 - val_accuracy: 0.0715\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.7499 - accuracy: 0.2750 - val_loss: 6.8999 - val_accuracy: 0.2445\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - 86s 161ms/step - loss: 6.7975 - accuracy: 0.2612 - val_loss: 6.9040 - val_accuracy: 0.2443\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.7722 - accuracy: 0.2608 - val_loss: 7.9024 - val_accuracy: 0.0694\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 6.7244 - accuracy: 0.2764 - val_loss: 9.0127 - val_accuracy: 0.0675\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - 86s 159ms/step - loss: 6.7284 - accuracy: 0.2729 - val_loss: 6.8101 - val_accuracy: 0.2457\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - 88s 164ms/step - loss: 6.7039 - accuracy: 0.2874 - val_loss: 6.7503 - val_accuracy: 0.2443\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.6988 - accuracy: 0.2887 - val_loss: 7.1511 - val_accuracy: 0.2445\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 6.7373 - accuracy: 0.2702 - val_loss: 6.9285 - val_accuracy: 0.2445\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.7704 - accuracy: 0.2640 - val_loss: 7.0016 - val_accuracy: 0.1532\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - 85s 157ms/step - loss: 6.6823 - accuracy: 0.2863 - val_loss: 6.7050 - val_accuracy: 0.2664\n",
      "Epoch 20/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 6.6276 - accuracy: 0.3054 - val_loss: 7.0215 - val_accuracy: 0.1914\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.6148 - accuracy: 0.3133 - val_loss: 6.7440 - val_accuracy: 0.2415\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 6.3148 - accuracy: 0.2916 - val_loss: 6.9800 - val_accuracy: 0.0673\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.0461 - accuracy: 0.2932 - val_loss: 8.1062 - val_accuracy: 0.0398\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 6.0404 - accuracy: 0.2956 - val_loss: 6.5653 - val_accuracy: 0.2224\n",
      "Epoch 25/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 5.9878 - accuracy: 0.3160 - val_loss: 6.1096 - val_accuracy: 0.2795\n",
      "Epoch 26/50\n",
      "537/537 [==============================] - 87s 163ms/step - loss: 6.0277 - accuracy: 0.3085 - val_loss: 6.4736 - val_accuracy: 0.1276\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - 85s 157ms/step - loss: 6.0566 - accuracy: 0.2975 - val_loss: 6.7653 - val_accuracy: 0.0254\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - 88s 163ms/step - loss: 5.9835 - accuracy: 0.3169 - val_loss: 6.9318 - val_accuracy: 0.1316\n",
      "Epoch 29/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 5.9394 - accuracy: 0.3277 - val_loss: 6.5388 - val_accuracy: 0.2138\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - 87s 163ms/step - loss: 6.1855 - accuracy: 0.2724 - val_loss: 6.6429 - val_accuracy: 0.0396\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.1647 - accuracy: 0.2633 - val_loss: 6.1252 - val_accuracy: 0.2764\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - 88s 164ms/step - loss: 6.0730 - accuracy: 0.2816 - val_loss: 6.5981 - val_accuracy: 0.0745\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - 85s 157ms/step - loss: 6.0086 - accuracy: 0.3002 - val_loss: 6.1309 - val_accuracy: 0.2818\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - 87s 163ms/step - loss: 5.9749 - accuracy: 0.3202 - val_loss: 6.4112 - val_accuracy: 0.2727\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - 87s 161ms/step - loss: 5.9846 - accuracy: 0.3182 - val_loss: 7.5290 - val_accuracy: 0.2450\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 6.1038 - accuracy: 0.2858 - val_loss: 8.4301 - val_accuracy: 0.0810\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 6.0693 - accuracy: 0.2922 - val_loss: 12.4168 - val_accuracy: 0.0068\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 5.9867 - accuracy: 0.3105 - val_loss: 6.4414 - val_accuracy: 0.2396\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 5.9259 - accuracy: 0.3304 - val_loss: 6.3447 - val_accuracy: 0.2573\n",
      "Epoch 40/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 6.0345 - accuracy: 0.3034 - val_loss: 6.0785 - val_accuracy: 0.2976\n",
      "Epoch 41/50\n",
      "537/537 [==============================] - 90s 167ms/step - loss: 5.9203 - accuracy: 0.3276 - val_loss: 7.4742 - val_accuracy: 0.1253\n",
      "Epoch 42/50\n",
      "537/537 [==============================] - 86s 159ms/step - loss: 5.8607 - accuracy: 0.3517 - val_loss: 6.8534 - val_accuracy: 0.1337\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - 89s 165ms/step - loss: 5.9592 - accuracy: 0.3298 - val_loss: 6.9723 - val_accuracy: 0.1276\n",
      "Epoch 44/50\n",
      "537/537 [==============================] - 83s 154ms/step - loss: 6.2009 - accuracy: 0.2507 - val_loss: 6.4711 - val_accuracy: 0.1113\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 6.0250 - accuracy: 0.3005 - val_loss: 6.5656 - val_accuracy: 0.0398\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 5.9817 - accuracy: 0.3158 - val_loss: 6.5164 - val_accuracy: 0.1807\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 6.0786 - accuracy: 0.2984 - val_loss: 6.5501 - val_accuracy: 0.0943\n",
      "Epoch 48/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 6.0358 - accuracy: 0.2998 - val_loss: 6.2027 - val_accuracy: 0.2627\n",
      "Epoch 49/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 5.9712 - accuracy: 0.3178 - val_loss: 6.3150 - val_accuracy: 0.1886\n",
      "Epoch 50/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 5.9063 - accuracy: 0.3354 - val_loss: 6.3260 - val_accuracy: 0.2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_ClassSteps_epochs-50_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_ClassSteps_epochs-50_batch-32\\assets\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"../logs/fit/\" + buildRunName(\"MobileNet_ClassSteps\", 50, 32)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=50,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "model.save(\"../models/\" + buildRunName(\"MobileNet_ClassSteps\", 50, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 655ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.       , 22.786198 ,  0.       , 23.690422 , 24.423817 ,\n",
       "         0.       ,  9.452552 ,  0.       ,  6.8637943,  7.3961463,\n",
       "        16.850552 , 46.771873 ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       , 20.524065 ,  0.       ,  0.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.io.read_file(\"../data/age/54_0_3_20170119210218868.jpg\")\n",
    "image = tf.image.decode_image(image, channels=3)\n",
    "image = np.expand_dims(image.numpy(), axis=0)\n",
    "image = tf.image.resize(image, (224,224))\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17179 validated image filenames.\n",
      "Found 4294 validated image filenames.\n",
      "Epoch 1/50\n",
      "537/537 [==============================] - 91s 163ms/step - loss: 169.3107 - accuracy: 0.0000e+00 - val_loss: 382.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 94.2150 - accuracy: 0.0000e+00 - val_loss: 676.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "537/537 [==============================] - 86s 159ms/step - loss: 72.7025 - accuracy: 0.0000e+00 - val_loss: 325.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "537/537 [==============================] - 83s 154ms/step - loss: 59.2470 - accuracy: 0.0000e+00 - val_loss: 324.2791 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 47.7464 - accuracy: 0.0000e+00 - val_loss: 449.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "537/537 [==============================] - 82s 153ms/step - loss: 40.9643 - accuracy: 0.0000e+00 - val_loss: 396.4093 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 37.7071 - accuracy: 0.0000e+00 - val_loss: 437.5473 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 33.8839 - accuracy: 0.0000e+00 - val_loss: 444.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "537/537 [==============================] - 87s 161ms/step - loss: 27.8016 - accuracy: 0.0000e+00 - val_loss: 348.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "537/537 [==============================] - 81s 151ms/step - loss: 24.8693 - accuracy: 0.0000e+00 - val_loss: 477.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 22.1544 - accuracy: 0.0000e+00 - val_loss: 279.8739 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 19.4516 - accuracy: 0.0000e+00 - val_loss: 312.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 18.7469 - accuracy: 0.0000e+00 - val_loss: 325.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 25.5112 - accuracy: 0.0000e+00 - val_loss: 322.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 16.2790 - accuracy: 0.0000e+00 - val_loss: 347.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 15.6591 - accuracy: 0.0000e+00 - val_loss: 313.9685 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 12.8758 - accuracy: 0.0000e+00 - val_loss: 360.7964 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 11.5265 - accuracy: 0.0000e+00 - val_loss: 258.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "537/537 [==============================] - 82s 153ms/step - loss: 18.7120 - accuracy: 0.0000e+00 - val_loss: 306.2780 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 15.9687 - accuracy: 0.0000e+00 - val_loss: 320.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "537/537 [==============================] - 83s 154ms/step - loss: 11.4969 - accuracy: 0.0000e+00 - val_loss: 313.9855 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 9.2047 - accuracy: 0.0000e+00 - val_loss: 218.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 8.4732 - accuracy: 0.0000e+00 - val_loss: 279.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 8.5967 - accuracy: 0.0000e+00 - val_loss: 344.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "537/537 [==============================] - 81s 151ms/step - loss: 9.0422 - accuracy: 0.0000e+00 - val_loss: 389.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 14.4687 - accuracy: 0.0000e+00 - val_loss: 254.1263 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "537/537 [==============================] - 82s 153ms/step - loss: 14.0267 - accuracy: 0.0000e+00 - val_loss: 262.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 10.3472 - accuracy: 0.0000e+00 - val_loss: 355.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "537/537 [==============================] - 86s 159ms/step - loss: 9.5532 - accuracy: 0.0000e+00 - val_loss: 268.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 6.7783 - accuracy: 0.0000e+00 - val_loss: 298.1535 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 6.0940 - accuracy: 0.0000e+00 - val_loss: 293.3760 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 6.3022 - accuracy: 0.0000e+00 - val_loss: 303.8282 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "537/537 [==============================] - 88s 163ms/step - loss: 6.7165 - accuracy: 0.0000e+00 - val_loss: 266.0496 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 7.4782 - accuracy: 0.0000e+00 - val_loss: 367.8702 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "537/537 [==============================] - 88s 164ms/step - loss: 7.1473 - accuracy: 0.0000e+00 - val_loss: 288.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 7.5659 - accuracy: 0.0000e+00 - val_loss: 322.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 6.6334 - accuracy: 0.0000e+00 - val_loss: 415.2431 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 6.4106 - accuracy: 0.0000e+00 - val_loss: 220.3876 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "537/537 [==============================] - 87s 162ms/step - loss: 6.0432 - accuracy: 0.0000e+00 - val_loss: 355.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 6.1362 - accuracy: 0.0000e+00 - val_loss: 215.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "537/537 [==============================] - 84s 156ms/step - loss: 5.8183 - accuracy: 0.0000e+00 - val_loss: 186.6320 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 5.7738 - accuracy: 0.0000e+00 - val_loss: 290.9819 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "537/537 [==============================] - 85s 157ms/step - loss: 5.8403 - accuracy: 0.0000e+00 - val_loss: 226.2873 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 5.6540 - accuracy: 0.0000e+00 - val_loss: 303.9758 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "537/537 [==============================] - 85s 158ms/step - loss: 5.8364 - accuracy: 0.0000e+00 - val_loss: 297.4018 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "537/537 [==============================] - 85s 159ms/step - loss: 13.6227 - accuracy: 0.0000e+00 - val_loss: 503.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "537/537 [==============================] - 83s 155ms/step - loss: 7.9134 - accuracy: 0.0000e+00 - val_loss: 346.0678 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 5.5380 - accuracy: 0.0000e+00 - val_loss: 148.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "537/537 [==============================] - 84s 157ms/step - loss: 4.5071 - accuracy: 0.0000e+00 - val_loss: 381.9283 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "537/537 [==============================] - 86s 160ms/step - loss: 3.6677 - accuracy: 0.0000e+00 - val_loss: 159.2779 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_Regression_epochs-50_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_Regression_epochs-50_batch-32\\assets\n"
     ]
    }
   ],
   "source": [
    "images = pd.read_json(\"../data_meta/age/meta_full.json\")\n",
    "\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=images,\n",
    "    x_col='Filepath',\n",
    "    y_col='Age',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=images,\n",
    "    x_col='Filepath',\n",
    "    y_col='Age',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "model = ModelLoader().loadMobileNetV1Age(train_images, False, False, 1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "log_dir = \"../logs/fit/\" + buildRunName(\"MobileNet_Regression\", 50, 32)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=50,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "model.save(\"../models/\" + buildRunName(\"MobileNet_Regression\", 50, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 379ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25.51753]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.io.read_file(\"../data/age/54_0_3_20170119210218868.jpg\")\n",
    "image = tf.image.decode_image(image, channels=3)\n",
    "image = np.expand_dims(image.numpy(), axis=0)\n",
    "image = tf.image.resize(image, (224,224))\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLambda)  (None, 224, 224, 3)  0          ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 224, 224, 3)  0          ['tf.math.truediv_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mobilenet_1.00_224 (Functional  (None, 7, 7, 1024)  3228864     ['tf.math.subtract_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 1024)        0           ['mobilenet_1.00_224[0][0]']     \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          262400      ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 1024)        0           ['mobilenet_1.00_224[0][0]']     \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 1024)        0           ['mobilenet_1.00_224[0][0]']     \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          131200      ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          32896       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1024)         0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " out_face_detection (Dense)     (None, 1)            1025        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " out_mask_detection (Dense)     (None, 1)            129         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " out_age_prediction (Dense)     (None, 1)            129         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,656,643\n",
      "Trainable params: 3,634,755\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from utils.modelLoader import ModelLoader\n",
    "\n",
    "model = ModelLoader().loadMobileNetV1Multi(10)\n",
    "model.summary()\n",
    "model.save(\"tes.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83c0f910dbfcbd19468ec888d5b427a34e5a43e434fc22f4c637efaf31b4d30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
