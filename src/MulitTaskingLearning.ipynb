{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils.modelLoader import ModelLoader\n",
    "import pandas as pd\n",
    "from utils.utilities import buildRunName\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "866/866 [==============================] - 63s 69ms/step - loss: 0.5495 - out_face_detection_loss: 0.0654 - out_mask_detection_loss: 0.0442 - out_age_prediction_loss: 1.5555 - out_face_detection_binary_accuracy: 0.9772 - out_mask_detection_binary_accuracy: 0.9858 - out_age_prediction_sparse_categorical_accuracy: 0.2238 - val_loss: 0.4620 - val_out_face_detection_loss: 0.0079 - val_out_mask_detection_loss: 0.0155 - val_out_age_prediction_loss: 1.3765 - val_out_face_detection_binary_accuracy: 0.9985 - val_out_mask_detection_binary_accuracy: 0.9953 - val_out_age_prediction_sparse_categorical_accuracy: 0.2686\n",
      "Epoch 2/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.4653 - out_face_detection_loss: 0.0143 - out_mask_detection_loss: 0.0165 - out_age_prediction_loss: 1.3791 - out_face_detection_binary_accuracy: 0.9954 - out_mask_detection_binary_accuracy: 0.9943 - out_age_prediction_sparse_categorical_accuracy: 0.2497 - val_loss: 0.4478 - val_out_face_detection_loss: 0.0044 - val_out_mask_detection_loss: 0.0095 - val_out_age_prediction_loss: 1.3433 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9966 - val_out_age_prediction_sparse_categorical_accuracy: 0.2735\n",
      "Epoch 3/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.4461 - out_face_detection_loss: 0.0102 - out_mask_detection_loss: 0.0128 - out_age_prediction_loss: 1.3288 - out_face_detection_binary_accuracy: 0.9968 - out_mask_detection_binary_accuracy: 0.9956 - out_age_prediction_sparse_categorical_accuracy: 0.2572 - val_loss: 0.4379 - val_out_face_detection_loss: 0.0032 - val_out_mask_detection_loss: 0.0097 - val_out_age_prediction_loss: 1.3140 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 4/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.4294 - out_face_detection_loss: 0.0113 - out_mask_detection_loss: 0.0102 - out_age_prediction_loss: 1.2797 - out_face_detection_binary_accuracy: 0.9961 - out_mask_detection_binary_accuracy: 0.9964 - out_age_prediction_sparse_categorical_accuracy: 0.2646 - val_loss: 0.4584 - val_out_face_detection_loss: 0.0031 - val_out_mask_detection_loss: 0.0094 - val_out_age_prediction_loss: 1.3768 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2706\n",
      "Epoch 5/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.4190 - out_face_detection_loss: 0.0107 - out_mask_detection_loss: 0.0086 - out_age_prediction_loss: 1.2504 - out_face_detection_binary_accuracy: 0.9964 - out_mask_detection_binary_accuracy: 0.9972 - out_age_prediction_sparse_categorical_accuracy: 0.2674 - val_loss: 0.4454 - val_out_face_detection_loss: 0.0033 - val_out_mask_detection_loss: 0.0107 - val_out_age_prediction_loss: 1.3358 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 6/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.4065 - out_face_detection_loss: 0.0085 - out_mask_detection_loss: 0.0078 - out_age_prediction_loss: 1.2154 - out_face_detection_binary_accuracy: 0.9969 - out_mask_detection_binary_accuracy: 0.9974 - out_age_prediction_sparse_categorical_accuracy: 0.2742 - val_loss: 0.4441 - val_out_face_detection_loss: 0.0027 - val_out_mask_detection_loss: 0.0124 - val_out_age_prediction_loss: 1.3306 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9966 - val_out_age_prediction_sparse_categorical_accuracy: 0.2765\n",
      "Epoch 7/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3940 - out_face_detection_loss: 0.0083 - out_mask_detection_loss: 0.0057 - out_age_prediction_loss: 1.1799 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9979 - out_age_prediction_sparse_categorical_accuracy: 0.2816 - val_loss: 0.4601 - val_out_face_detection_loss: 0.0026 - val_out_mask_detection_loss: 0.0131 - val_out_age_prediction_loss: 1.3785 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9965 - val_out_age_prediction_sparse_categorical_accuracy: 0.2732\n",
      "Epoch 8/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3866 - out_face_detection_loss: 0.0086 - out_mask_detection_loss: 0.0061 - out_age_prediction_loss: 1.1567 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9977 - out_age_prediction_sparse_categorical_accuracy: 0.2815 - val_loss: 0.4673 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0123 - val_out_age_prediction_loss: 1.4015 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2713\n",
      "Epoch 9/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3775 - out_face_detection_loss: 0.0089 - out_mask_detection_loss: 0.0060 - out_age_prediction_loss: 1.1290 - out_face_detection_binary_accuracy: 0.9972 - out_mask_detection_binary_accuracy: 0.9979 - out_age_prediction_sparse_categorical_accuracy: 0.2869 - val_loss: 0.4815 - val_out_face_detection_loss: 0.0027 - val_out_mask_detection_loss: 0.0132 - val_out_age_prediction_loss: 1.4432 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9961 - val_out_age_prediction_sparse_categorical_accuracy: 0.2738\n",
      "Epoch 10/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3669 - out_face_detection_loss: 0.0086 - out_mask_detection_loss: 0.0048 - out_age_prediction_loss: 1.0983 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9984 - out_age_prediction_sparse_categorical_accuracy: 0.2951 - val_loss: 0.4816 - val_out_face_detection_loss: 0.0025 - val_out_mask_detection_loss: 0.0091 - val_out_age_prediction_loss: 1.4477 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9975 - val_out_age_prediction_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 11/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3569 - out_face_detection_loss: 0.0076 - out_mask_detection_loss: 0.0049 - out_age_prediction_loss: 1.0690 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9983 - out_age_prediction_sparse_categorical_accuracy: 0.2995 - val_loss: 0.4785 - val_out_face_detection_loss: 0.0021 - val_out_mask_detection_loss: 0.0069 - val_out_age_prediction_loss: 1.4411 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9981 - val_out_age_prediction_sparse_categorical_accuracy: 0.2774\n",
      "Epoch 12/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3523 - out_face_detection_loss: 0.0091 - out_mask_detection_loss: 0.0049 - out_age_prediction_loss: 1.0536 - out_face_detection_binary_accuracy: 0.9969 - out_mask_detection_binary_accuracy: 0.9984 - out_age_prediction_sparse_categorical_accuracy: 0.3027 - val_loss: 0.5044 - val_out_face_detection_loss: 0.0021 - val_out_mask_detection_loss: 0.0103 - val_out_age_prediction_loss: 1.5160 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2661\n",
      "Epoch 13/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3398 - out_face_detection_loss: 0.0086 - out_mask_detection_loss: 0.0046 - out_age_prediction_loss: 1.0165 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9986 - out_age_prediction_sparse_categorical_accuracy: 0.3123 - val_loss: 0.5057 - val_out_face_detection_loss: 0.0017 - val_out_mask_detection_loss: 0.0123 - val_out_age_prediction_loss: 1.5183 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2703\n",
      "Epoch 14/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3334 - out_face_detection_loss: 0.0083 - out_mask_detection_loss: 0.0041 - out_age_prediction_loss: 0.9979 - out_face_detection_binary_accuracy: 0.9974 - out_mask_detection_binary_accuracy: 0.9986 - out_age_prediction_sparse_categorical_accuracy: 0.3132 - val_loss: 0.5102 - val_out_face_detection_loss: 0.0018 - val_out_mask_detection_loss: 0.0133 - val_out_age_prediction_loss: 1.5311 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9968 - val_out_age_prediction_sparse_categorical_accuracy: 0.2676\n",
      "Epoch 15/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3228 - out_face_detection_loss: 0.0084 - out_mask_detection_loss: 0.0050 - out_age_prediction_loss: 0.9649 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9982 - out_age_prediction_sparse_categorical_accuracy: 0.3231 - val_loss: 0.5070 - val_out_face_detection_loss: 0.0017 - val_out_mask_detection_loss: 0.0091 - val_out_age_prediction_loss: 1.5256 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2666\n",
      "Epoch 16/50\n",
      "866/866 [==============================] - 58s 68ms/step - loss: 0.3156 - out_face_detection_loss: 0.0088 - out_mask_detection_loss: 0.0030 - out_age_prediction_loss: 0.9447 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9992 - out_age_prediction_sparse_categorical_accuracy: 0.3237 - val_loss: 0.5192 - val_out_face_detection_loss: 0.0020 - val_out_mask_detection_loss: 0.0184 - val_out_age_prediction_loss: 1.5530 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9951 - val_out_age_prediction_sparse_categorical_accuracy: 0.2693\n",
      "Epoch 17/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3144 - out_face_detection_loss: 0.0083 - out_mask_detection_loss: 0.0032 - out_age_prediction_loss: 0.9414 - out_face_detection_binary_accuracy: 0.9975 - out_mask_detection_binary_accuracy: 0.9990 - out_age_prediction_sparse_categorical_accuracy: 0.3274 - val_loss: 0.5426 - val_out_face_detection_loss: 0.0022 - val_out_mask_detection_loss: 0.0123 - val_out_age_prediction_loss: 1.6296 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2649\n",
      "Epoch 18/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.3026 - out_face_detection_loss: 0.0068 - out_mask_detection_loss: 0.0044 - out_age_prediction_loss: 0.9058 - out_face_detection_binary_accuracy: 0.9979 - out_mask_detection_binary_accuracy: 0.9987 - out_age_prediction_sparse_categorical_accuracy: 0.3309 - val_loss: 0.5391 - val_out_face_detection_loss: 0.0019 - val_out_mask_detection_loss: 0.0111 - val_out_age_prediction_loss: 1.6207 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2624\n",
      "Epoch 19/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2959 - out_face_detection_loss: 0.0109 - out_mask_detection_loss: 0.0023 - out_age_prediction_loss: 0.8835 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3400 - val_loss: 0.5734 - val_out_face_detection_loss: 0.0026 - val_out_mask_detection_loss: 0.0211 - val_out_age_prediction_loss: 1.7139 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9960 - val_out_age_prediction_sparse_categorical_accuracy: 0.2646\n",
      "Epoch 20/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2902 - out_face_detection_loss: 0.0074 - out_mask_detection_loss: 0.0041 - out_age_prediction_loss: 0.8679 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9986 - out_age_prediction_sparse_categorical_accuracy: 0.3412 - val_loss: 0.6126 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0112 - val_out_age_prediction_loss: 1.8428 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9976 - val_out_age_prediction_sparse_categorical_accuracy: 0.2637\n",
      "Epoch 21/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2862 - out_face_detection_loss: 0.0090 - out_mask_detection_loss: 0.0036 - out_age_prediction_loss: 0.8548 - out_face_detection_binary_accuracy: 0.9964 - out_mask_detection_binary_accuracy: 0.9988 - out_age_prediction_sparse_categorical_accuracy: 0.3475 - val_loss: 0.5549 - val_out_face_detection_loss: 0.0021 - val_out_mask_detection_loss: 0.0223 - val_out_age_prediction_loss: 1.6573 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9963 - val_out_age_prediction_sparse_categorical_accuracy: 0.2578\n",
      "Epoch 22/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2832 - out_face_detection_loss: 0.0077 - out_mask_detection_loss: 0.0030 - out_age_prediction_loss: 0.8474 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9990 - out_age_prediction_sparse_categorical_accuracy: 0.3468 - val_loss: 0.5861 - val_out_face_detection_loss: 0.0024 - val_out_mask_detection_loss: 0.0092 - val_out_age_prediction_loss: 1.7643 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9973 - val_out_age_prediction_sparse_categorical_accuracy: 0.2378\n",
      "Epoch 23/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2746 - out_face_detection_loss: 0.0094 - out_mask_detection_loss: 0.0032 - out_age_prediction_loss: 0.8197 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3540 - val_loss: 0.5868 - val_out_face_detection_loss: 0.0027 - val_out_mask_detection_loss: 0.0154 - val_out_age_prediction_loss: 1.7601 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9963 - val_out_age_prediction_sparse_categorical_accuracy: 0.2521\n",
      "Epoch 24/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2702 - out_face_detection_loss: 0.0097 - out_mask_detection_loss: 0.0025 - out_age_prediction_loss: 0.8067 - out_face_detection_binary_accuracy: 0.9965 - out_mask_detection_binary_accuracy: 0.9992 - out_age_prediction_sparse_categorical_accuracy: 0.3580 - val_loss: 0.5953 - val_out_face_detection_loss: 0.0024 - val_out_mask_detection_loss: 0.0134 - val_out_age_prediction_loss: 1.7883 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9973 - val_out_age_prediction_sparse_categorical_accuracy: 0.2501\n",
      "Epoch 25/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2663 - out_face_detection_loss: 0.0101 - out_mask_detection_loss: 0.0018 - out_age_prediction_loss: 0.7951 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9994 - out_age_prediction_sparse_categorical_accuracy: 0.3601 - val_loss: 0.6804 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0133 - val_out_age_prediction_loss: 2.0463 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 26/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2641 - out_face_detection_loss: 0.0096 - out_mask_detection_loss: 0.0036 - out_age_prediction_loss: 0.7872 - out_face_detection_binary_accuracy: 0.9969 - out_mask_detection_binary_accuracy: 0.9989 - out_age_prediction_sparse_categorical_accuracy: 0.3619 - val_loss: 0.6294 - val_out_face_detection_loss: 0.0029 - val_out_mask_detection_loss: 0.0158 - val_out_age_prediction_loss: 1.8884 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9965 - val_out_age_prediction_sparse_categorical_accuracy: 0.2471\n",
      "Epoch 27/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2536 - out_face_detection_loss: 0.0078 - out_mask_detection_loss: 0.0024 - out_age_prediction_loss: 0.7581 - out_face_detection_binary_accuracy: 0.9976 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3664 - val_loss: 0.6519 - val_out_face_detection_loss: 0.0020 - val_out_mask_detection_loss: 0.0107 - val_out_age_prediction_loss: 1.9627 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9976 - val_out_age_prediction_sparse_categorical_accuracy: 0.2415\n",
      "Epoch 28/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2501 - out_face_detection_loss: 0.0074 - out_mask_detection_loss: 0.0020 - out_age_prediction_loss: 0.7484 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9995 - out_age_prediction_sparse_categorical_accuracy: 0.3696 - val_loss: 0.6676 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0104 - val_out_age_prediction_loss: 2.0102 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2383\n",
      "Epoch 29/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2468 - out_face_detection_loss: 0.0103 - out_mask_detection_loss: 0.0028 - out_age_prediction_loss: 0.7349 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3743 - val_loss: 0.6607 - val_out_face_detection_loss: 0.0021 - val_out_mask_detection_loss: 0.0190 - val_out_age_prediction_loss: 1.9811 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9965 - val_out_age_prediction_sparse_categorical_accuracy: 0.2469\n",
      "Epoch 30/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2420 - out_face_detection_loss: 0.0094 - out_mask_detection_loss: 0.0030 - out_age_prediction_loss: 0.7210 - out_face_detection_binary_accuracy: 0.9968 - out_mask_detection_binary_accuracy: 0.9989 - out_age_prediction_sparse_categorical_accuracy: 0.3784 - val_loss: 0.6505 - val_out_face_detection_loss: 0.0024 - val_out_mask_detection_loss: 0.0175 - val_out_age_prediction_loss: 1.9512 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2533\n",
      "Epoch 31/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2402 - out_face_detection_loss: 0.0102 - out_mask_detection_loss: 0.0032 - out_age_prediction_loss: 0.7145 - out_face_detection_binary_accuracy: 0.9967 - out_mask_detection_binary_accuracy: 0.9992 - out_age_prediction_sparse_categorical_accuracy: 0.3786 - val_loss: 0.6763 - val_out_face_detection_loss: 0.0021 - val_out_mask_detection_loss: 0.0132 - val_out_age_prediction_loss: 2.0341 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9975 - val_out_age_prediction_sparse_categorical_accuracy: 0.2430\n",
      "Epoch 32/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2356 - out_face_detection_loss: 0.0113 - out_mask_detection_loss: 5.9622e-04 - out_age_prediction_loss: 0.7021 - out_face_detection_binary_accuracy: 0.9964 - out_mask_detection_binary_accuracy: 0.9998 - out_age_prediction_sparse_categorical_accuracy: 0.3800 - val_loss: 0.6655 - val_out_face_detection_loss: 0.0022 - val_out_mask_detection_loss: 0.0111 - val_out_age_prediction_loss: 2.0033 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2410\n",
      "Epoch 33/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2315 - out_face_detection_loss: 0.0078 - out_mask_detection_loss: 0.0020 - out_age_prediction_loss: 0.6916 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9994 - out_age_prediction_sparse_categorical_accuracy: 0.3833 - val_loss: 0.7265 - val_out_face_detection_loss: 0.0025 - val_out_mask_detection_loss: 0.0127 - val_out_age_prediction_loss: 2.1862 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 34/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2303 - out_face_detection_loss: 0.0092 - out_mask_detection_loss: 0.0033 - out_age_prediction_loss: 0.6853 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3858 - val_loss: 0.7122 - val_out_face_detection_loss: 0.0025 - val_out_mask_detection_loss: 0.0186 - val_out_age_prediction_loss: 2.1370 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2432\n",
      "Epoch 35/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2226 - out_face_detection_loss: 0.0092 - out_mask_detection_loss: 0.0026 - out_age_prediction_loss: 0.6626 - out_face_detection_binary_accuracy: 0.9968 - out_mask_detection_binary_accuracy: 0.9991 - out_age_prediction_sparse_categorical_accuracy: 0.3911 - val_loss: 0.7300 - val_out_face_detection_loss: 0.0028 - val_out_mask_detection_loss: 0.0141 - val_out_age_prediction_loss: 2.1952 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2423\n",
      "Epoch 36/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2259 - out_face_detection_loss: 0.0088 - out_mask_detection_loss: 0.0021 - out_age_prediction_loss: 0.6737 - out_face_detection_binary_accuracy: 0.9972 - out_mask_detection_binary_accuracy: 0.9995 - out_age_prediction_sparse_categorical_accuracy: 0.3859 - val_loss: 0.7276 - val_out_face_detection_loss: 0.0025 - val_out_mask_detection_loss: 0.0148 - val_out_age_prediction_loss: 2.1876 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2422\n",
      "Epoch 37/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2173 - out_face_detection_loss: 0.0097 - out_mask_detection_loss: 0.0018 - out_age_prediction_loss: 0.6469 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9995 - out_age_prediction_sparse_categorical_accuracy: 0.3927 - val_loss: 0.7589 - val_out_face_detection_loss: 0.0028 - val_out_mask_detection_loss: 0.0175 - val_out_age_prediction_loss: 2.2795 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9968 - val_out_age_prediction_sparse_categorical_accuracy: 0.2346\n",
      "Epoch 38/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2167 - out_face_detection_loss: 0.0083 - out_mask_detection_loss: 7.6748e-04 - out_age_prediction_loss: 0.6474 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9997 - out_age_prediction_sparse_categorical_accuracy: 0.3942 - val_loss: 0.7283 - val_out_face_detection_loss: 0.0026 - val_out_mask_detection_loss: 0.0153 - val_out_age_prediction_loss: 2.1889 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9971 - val_out_age_prediction_sparse_categorical_accuracy: 0.2516\n",
      "Epoch 39/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2137 - out_face_detection_loss: 0.0094 - out_mask_detection_loss: 0.0032 - out_age_prediction_loss: 0.6351 - out_face_detection_binary_accuracy: 0.9969 - out_mask_detection_binary_accuracy: 0.9990 - out_age_prediction_sparse_categorical_accuracy: 0.3988 - val_loss: 0.7492 - val_out_face_detection_loss: 0.0032 - val_out_mask_detection_loss: 0.0167 - val_out_age_prediction_loss: 2.2504 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9968 - val_out_age_prediction_sparse_categorical_accuracy: 0.2433\n",
      "Epoch 40/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2114 - out_face_detection_loss: 0.0088 - out_mask_detection_loss: 0.0015 - out_age_prediction_loss: 0.6304 - out_face_detection_binary_accuracy: 0.9971 - out_mask_detection_binary_accuracy: 0.9995 - out_age_prediction_sparse_categorical_accuracy: 0.3977 - val_loss: 0.7507 - val_out_face_detection_loss: 0.0033 - val_out_mask_detection_loss: 0.0149 - val_out_age_prediction_loss: 2.2568 - val_out_face_detection_binary_accuracy: 0.9988 - val_out_mask_detection_binary_accuracy: 0.9970 - val_out_age_prediction_sparse_categorical_accuracy: 0.2501\n",
      "Epoch 41/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.2088 - out_face_detection_loss: 0.0102 - out_mask_detection_loss: 0.0015 - out_age_prediction_loss: 0.6208 - out_face_detection_binary_accuracy: 0.9968 - out_mask_detection_binary_accuracy: 0.9996 - out_age_prediction_sparse_categorical_accuracy: 0.4016 - val_loss: 0.7611 - val_out_face_detection_loss: 0.0027 - val_out_mask_detection_loss: 0.0177 - val_out_age_prediction_loss: 2.2859 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9966 - val_out_age_prediction_sparse_categorical_accuracy: 0.2396\n",
      "Epoch 42/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2131 - out_face_detection_loss: 0.0104 - out_mask_detection_loss: 0.0046 - out_age_prediction_loss: 0.6307 - out_face_detection_binary_accuracy: 0.9966 - out_mask_detection_binary_accuracy: 0.9989 - out_age_prediction_sparse_categorical_accuracy: 0.4007 - val_loss: 0.7779 - val_out_face_detection_loss: 0.0024 - val_out_mask_detection_loss: 0.0160 - val_out_age_prediction_loss: 2.3389 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9978 - val_out_age_prediction_sparse_categorical_accuracy: 0.2334\n",
      "Epoch 43/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2031 - out_face_detection_loss: 0.0081 - out_mask_detection_loss: 6.6271e-04 - out_age_prediction_loss: 0.6068 - out_face_detection_binary_accuracy: 0.9974 - out_mask_detection_binary_accuracy: 0.9997 - out_age_prediction_sparse_categorical_accuracy: 0.4045 - val_loss: 0.7917 - val_out_face_detection_loss: 0.0026 - val_out_mask_detection_loss: 0.0208 - val_out_age_prediction_loss: 2.3758 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9966 - val_out_age_prediction_sparse_categorical_accuracy: 0.2459\n",
      "Epoch 44/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2056 - out_face_detection_loss: 0.0095 - out_mask_detection_loss: 0.0037 - out_age_prediction_loss: 0.6098 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9993 - out_age_prediction_sparse_categorical_accuracy: 0.4036 - val_loss: 0.8238 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0334 - val_out_age_prediction_loss: 2.4607 - val_out_face_detection_binary_accuracy: 0.9992 - val_out_mask_detection_binary_accuracy: 0.9961 - val_out_age_prediction_sparse_categorical_accuracy: 0.2292\n",
      "Epoch 45/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.2011 - out_face_detection_loss: 0.0080 - out_mask_detection_loss: 0.0013 - out_age_prediction_loss: 0.5999 - out_face_detection_binary_accuracy: 0.9974 - out_mask_detection_binary_accuracy: 0.9995 - out_age_prediction_sparse_categorical_accuracy: 0.4074 - val_loss: 0.7796 - val_out_face_detection_loss: 0.0019 - val_out_mask_detection_loss: 0.0183 - val_out_age_prediction_loss: 2.3422 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9976 - val_out_age_prediction_sparse_categorical_accuracy: 0.2380\n",
      "Epoch 46/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.1960 - out_face_detection_loss: 0.0082 - out_mask_detection_loss: 0.0036 - out_age_prediction_loss: 0.5820 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9992 - out_age_prediction_sparse_categorical_accuracy: 0.4120 - val_loss: 0.8335 - val_out_face_detection_loss: 0.0024 - val_out_mask_detection_loss: 0.0119 - val_out_age_prediction_loss: 2.5115 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9980 - val_out_age_prediction_sparse_categorical_accuracy: 0.2408\n",
      "Epoch 47/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.1940 - out_face_detection_loss: 0.0101 - out_mask_detection_loss: 0.0010 - out_age_prediction_loss: 0.5766 - out_face_detection_binary_accuracy: 0.9965 - out_mask_detection_binary_accuracy: 0.9997 - out_age_prediction_sparse_categorical_accuracy: 0.4128 - val_loss: 0.8126 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0114 - val_out_age_prediction_loss: 2.4489 - val_out_face_detection_binary_accuracy: 0.9990 - val_out_mask_detection_binary_accuracy: 0.9976 - val_out_age_prediction_sparse_categorical_accuracy: 0.2364\n",
      "Epoch 48/50\n",
      "866/866 [==============================] - 58s 67ms/step - loss: 0.1869 - out_face_detection_loss: 0.0073 - out_mask_detection_loss: 7.1932e-04 - out_age_prediction_loss: 0.5584 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9999 - out_age_prediction_sparse_categorical_accuracy: 0.4179 - val_loss: 0.8145 - val_out_face_detection_loss: 0.0022 - val_out_mask_detection_loss: 0.0192 - val_out_age_prediction_loss: 2.4467 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9968 - val_out_age_prediction_sparse_categorical_accuracy: 0.2472\n",
      "Epoch 49/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.1956 - out_face_detection_loss: 0.0104 - out_mask_detection_loss: 0.0020 - out_age_prediction_loss: 0.5803 - out_face_detection_binary_accuracy: 0.9970 - out_mask_detection_binary_accuracy: 0.9996 - out_age_prediction_sparse_categorical_accuracy: 0.4137 - val_loss: 0.8192 - val_out_face_detection_loss: 0.0025 - val_out_mask_detection_loss: 0.0142 - val_out_age_prediction_loss: 2.4658 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9975 - val_out_age_prediction_sparse_categorical_accuracy: 0.2489\n",
      "Epoch 50/50\n",
      "866/866 [==============================] - 59s 68ms/step - loss: 0.1859 - out_face_detection_loss: 0.0082 - out_mask_detection_loss: 0.0063 - out_age_prediction_loss: 0.5488 - out_face_detection_binary_accuracy: 0.9973 - out_mask_detection_binary_accuracy: 0.9990 - out_age_prediction_sparse_categorical_accuracy: 0.4199 - val_loss: 0.8445 - val_out_face_detection_loss: 0.0023 - val_out_mask_detection_loss: 0.0228 - val_out_age_prediction_loss: 2.5340 - val_out_face_detection_binary_accuracy: 0.9993 - val_out_mask_detection_binary_accuracy: 0.9981 - val_out_age_prediction_sparse_categorical_accuracy: 0.2511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_MultiTask_epochs-50_batch-32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/MobileNet_MultiTask_epochs-50_batch-32\\assets\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def decode_img(img_path):\n",
    "    \"\"\"\n",
    "    function read image from filepath and format it into a tensor\n",
    "    :param img_path: filepath of the image\n",
    "    :return: decodes image as tensor\n",
    "    \"\"\"\n",
    "    image_size = (224, 224)\n",
    "    num_channels = 3\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(\n",
    "        img, channels=num_channels, expand_animations=False\n",
    "    )\n",
    "    img = tf.image.resize(img, image_size, method=\"bilinear\")\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img\n",
    "\n",
    "def process_path(file_path, labels):\n",
    "    label = {'out_age_prediction': tf.reshape(tf.keras.backend.cast(labels[0], tf.keras.backend.floatx()), (1, 1)),\n",
    "             'out_face_detection': tf.reshape(tf.keras.backend.cast(labels[1], tf.keras.backend.floatx()), (1, 1)),\n",
    "             'out_mask_detection': tf.reshape(tf.keras.backend.cast(labels[2], tf.keras.backend.floatx()), (1, 1))}\n",
    "    img = decode_img(file_path)\n",
    "    return img, label\n",
    "\n",
    "def group_ages(age: int):\n",
    "    current_range = [\n",
    "        ( 0, 0),\n",
    "        ( 1,10),\n",
    "        (11,20),\n",
    "        (21,30),\n",
    "        (31,40),\n",
    "        (41,50),\n",
    "        (51,60),\n",
    "        (61,70),\n",
    "        (71,80),\n",
    "        (81,90),\n",
    "        (91,100)\n",
    "    ]\n",
    "    if isinstance(age, int) and age >= current_range[0] and age <= current_range[1]:\n",
    "        return current_range.index(current_range)\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "def create_dataset(data):\n",
    "    data = tf.data.Dataset.from_tensor_slices(\n",
    "        (data[\"Filepath\"], data[[\"Age\", \"Face\", \"Mask\"]]))\n",
    "    ds = data.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(32)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "metaData = pd.read_json(\"../data_meta/meta_all_cropped.json\")\n",
    "metaData = metaData.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "metaData_train = metaData.iloc[0:int(metaData.__len__() * 0.7)]\n",
    "metaData_val =  metaData.iloc[int(metaData.__len__() * 0.7)+1:int(metaData.__len__() * 0.85)]\n",
    "metaData_test = metaData.iloc[int(metaData.__len__() * 0.85)+1:]\n",
    "\n",
    "train_ds = create_dataset(metaData_train)\n",
    "val_ds = create_dataset(metaData_val)\n",
    "test_ds = create_dataset(metaData_test)\n",
    "\n",
    "model = ModelLoader().loadMobileNetV1Multi(10)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss={\n",
    "        \"out_age_prediction\": tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1),\n",
    "        \"out_face_detection\": tf.keras.losses.BinaryCrossentropy(),\n",
    "        \"out_mask_detection\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"out_age_prediction\": 0.33,\n",
    "        \"out_face_detection\": 0.33,\n",
    "        \"out_mask_detection\": 0.33,\n",
    "    },\n",
    "    metrics={\n",
    "        \"out_age_prediction\": tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        \"out_face_detection\": tf.keras.metrics.BinaryAccuracy(),\n",
    "        \"out_mask_detection\": tf.keras.metrics.BinaryAccuracy(),\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "log_dir = \"../logs/fit/\" + buildRunName(\"MobileNet_MultiTask\", 50, 32)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "model.save(\"../models/\" + buildRunName(\"MobileNet_MultiTask\", 50, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 10s 52ms/step - loss: 0.8817 - out_face_detection_loss: 0.0052 - out_mask_detection_loss: 0.0249 - out_age_prediction_loss: 2.6418 - out_face_detection_binary_accuracy: 0.9988 - out_mask_detection_binary_accuracy: 0.9981 - out_age_prediction_sparse_categorical_accuracy: 0.2472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8817152976989746,\n",
       " 0.005206682253628969,\n",
       " 0.024870164692401886,\n",
       " 2.64178729057312,\n",
       " 0.9988203644752502,\n",
       " 0.9981462955474854,\n",
       " 0.24721941351890564]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = tf.io.read_file(\"../data/age/99_1_0_20170113013141679.jpg\")\n",
    "image = tf.image.decode_image(image, channels=3)\n",
    "image = np.expand_dims(image.numpy(), axis=0)\n",
    "image = tf.image.resize(image, (224,224))\n",
    "model.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metaData = pd.read_json(\"../data_meta/meta_all.json\")\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((metaData[\"Filepath\"], metaData[[\"Face\", \"Mask\", \"Age\"]]))\n",
    "\n",
    "def _parse_function(filename, labels:tf.Tensor):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(\n",
    "        image, channels=3\n",
    "    )  # Channels needed because some test images are b/w\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image.set_shape((224, 224, 3))\n",
    "    \n",
    "    labelsDict = dict()\n",
    "    try:\n",
    "        labelsDict =  {'out_age_prediction': tf.reshape(tf.keras.backend.cast(labels[0], tf.keras.backend.floatx()), (-1, 1)),\n",
    "            'out_face_detection': tf.reshape(tf.keras.backend.cast(labels[1], tf.keras.backend.floatx()), (-1, 1)),\n",
    "            'out_mask_detection': tf.reshape(tf.keras.backend.cast(labels[2], tf.keras.backend.floatx()), (-1, 1))}\n",
    "    except:\n",
    "        pass\n",
    "    print(labelsDict)\n",
    "    return image, labelsDict\n",
    "\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "dataset_train = dataset.take(dataset.__len__().numpy() * 0.8)\n",
    "dataset_val = dataset.skip(dataset.__len__().numpy() * 0.8).take(dataset.__len__().numpy() * 0.2)\n",
    "dataset_train = dataset_train.batch(32)\n",
    "dataset_val = dataset_val.batch(32)\n",
    "\n",
    "# train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rescale=1.0 / 255, validation_split=0.2\n",
    "# )\n",
    "\n",
    "# train_images = train_generator.flow_from_dataframe(\n",
    "#     dataframe=metaData,\n",
    "#     x_col=\"Filepath\",\n",
    "#     y_col=[\"Face\", \"Mask\", \"Age\"],\n",
    "#     target_size=(224, 224),\n",
    "#     color_mode=\"rgb\",\n",
    "#     class_mode=\"raw\",\n",
    "#     batch_size=32,\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "#     subset=\"training\",\n",
    "# )\n",
    "\n",
    "\n",
    "# val_images = train_generator.flow_from_dataframe(\n",
    "#     dataframe=metaData,\n",
    "#     x_col=\"Filepath\",\n",
    "#     y_col=[\"Face\", \"Mask\", \"Age\"],\n",
    "#     target_size=(224, 224),\n",
    "#     color_mode=\"rgb\",\n",
    "#     class_mode=\"raw\",\n",
    "#     batch_size=32,\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "#     subset=\"validation\",\n",
    "# )\n",
    "\n",
    "model: tf.keras.Model = ModelLoader().loadMobileNetV1Multi(11)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss={\n",
    "        \"out_age_prediction\": tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            ignore_class=-1\n",
    "        ),\n",
    "        \"out_face_detection\": tf.keras.losses.BinaryCrossentropy(),\n",
    "        \"out_mask_detection\": tf.keras.losses.BinaryCrossentropy(),\n",
    "    },\n",
    "    loss_weights={'out_face_detection': 0.33,\n",
    "                    'out_mask_detection': 0.33,\n",
    "                    'out_age_prediction': 0.33},\n",
    "    metrics={\n",
    "        \"out_age_prediction\": [tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()],\n",
    "        \"out_face_detection\": tf.keras.metrics.Accuracy(),\n",
    "        \"out_mask_detection\": tf.keras.metrics.Accuracy(),\n",
    "    },\n",
    ")\n",
    "\n",
    "log_dir = \"../logs/fit/\" + buildRunName(\"MobileNet_Multi_Dropout-20\", 10, 32)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    validation_data=dataset_val,\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "\n",
    "model.save(\"../models/\" + buildRunName(\"MobileNet_Multi_Dropout-20\", 10, 32))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a83c0f910dbfcbd19468ec888d5b427a34e5a43e434fc22f4c637efaf31b4d30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
